# -*- coding: utf-8 -*-
"""Twitter_sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mLNOC5YOvjoz0ejvNWFEsjkJs8DtizmM
"""

# Import required libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score
from gensim.models import Word2Vec
import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')

# Load the Twitter dataset (replace with your actual data loading)
# Assuming you have a CSV file with 'text' and 'sentiment' columns
df = pd.read_csv('/content/Sentiment Analysis Dataset.csv')
df=df[0:10000]

len(df)

df.dropna(subset=['text'], inplace=True)

# Preprocess the text data
df['tokens'] = df['text'].apply(lambda x: word_tokenize(str(x))) # Ensure the input to word_tokenize is always a string

# Train Word2Vec model
w2v_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)

# Function to get Word2Vec features
def get_word2vec_features(tokens):
    return np.mean([w2v_model.wv[word] for word in tokens if word in w2v_model.wv], axis=0)

# Create Word2Vec features
df['w2v_features'] = df['tokens'].apply(get_word2vec_features)

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=5000)

tfidf_features = tfidf.fit_transform(df['text'])

# Combine features
X = np.hstack((tfidf_features.toarray(), np.vstack(df['w2v_features'])))
y = df['sentiment']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Initialize classifiers
classifiers = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'XGBoost': XGBClassifier(),
    'LightGBM': LGBMClassifier()
}

# Train and evaluate classifiers
results = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name} Accuracy: {accuracy:.4f}")

# Print overall results
print("\nOverall Results:")
for name, accuracy in results.items():
    print(f"{name}: {accuracy:.4f}")

# Calculate average accuracy
avg_accuracy = np.mean(list(results.values()))
print(f"\nAverage Accuracy: {avg_accuracy:.4f}")

